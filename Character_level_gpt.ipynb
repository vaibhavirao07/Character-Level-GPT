{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Character Level GPT trained on Shakespeare Data"
      ],
      "metadata": {
        "id": "EnpQ__Ip-MWj"
      },
      "id": "EnpQ__Ip-MWj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a18dc73c-7a5b-464d-9eab-016a8a9f4e5e",
      "metadata": {
        "id": "a18dc73c-7a5b-464d-9eab-016a8a9f4e5e",
        "outputId": "b3b92b9d-f16e-4128-fad3-3ddd4462915b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2)\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.2)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.1.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (4.7.1)\n",
            "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (2023.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchvision) (2.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchvision) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torchvision\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "661aa6ae-24d1-435b-bf3d-8dc4bbe28c2c",
      "metadata": {
        "id": "661aa6ae-24d1-435b-bf3d-8dc4bbe28c2c"
      },
      "source": [
        "Step 1: Load the Shakespeare data and preview first 500 characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bad52e40-391c-406e-8474-9bbdceb3d4a8",
      "metadata": {
        "id": "bad52e40-391c-406e-8474-9bbdceb3d4a8",
        "outputId": "9e4e5439-1baa-43f2-b157-46e7e52c5752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total characters in dataset: 1115394\n",
            "Sample text:\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "file_path = \"input.txt\"\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(f\"Total characters in dataset: {len(text)}\")\n",
        "print(f\"Sample text:\\n{text[:500]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a0c1a6c-0331-4ada-a939-0b0874f19360",
      "metadata": {
        "id": "1a0c1a6c-0331-4ada-a939-0b0874f19360"
      },
      "source": [
        "Step 2: Tokenize at char level, get all unique characters and create mappings for char to index and vice vera."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6151401b-ac7d-4840-8b1f-c95347a578d1",
      "metadata": {
        "id": "6151401b-ac7d-4840-8b1f-c95347a578d1",
        "outputId": "8b1b5698-af2e-4108-a23a-7e3f68d3880c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 65\n",
            "Character Mappings:\n",
            "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
        "idx_to_char = {idx: char for idx, char in enumerate(chars)}\n",
        "\n",
        "print(f\"Vocabulary Size: {vocab_size}\")\n",
        "print(f\"Character Mappings:\\n{char_to_idx}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49ea9c5c-dcf1-40b2-b285-4de916836f9f",
      "metadata": {
        "id": "49ea9c5c-dcf1-40b2-b285-4de916836f9f"
      },
      "source": [
        "Srep 3: convert text to integer and print first 100 encided characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "013f8d6c-1e37-42d3-a7ea-65addebb713c",
      "metadata": {
        "id": "013f8d6c-1e37-42d3-a7ea-65addebb713c",
        "outputId": "33d92c15-7947-4f75-a402-651866f8a45d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded text sample: [18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
            "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
            " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
            "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
            "  0 37 53 59]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "encoded_text = np.array([char_to_idx[c] for c in text], dtype=np.int32)\n",
        "\n",
        "print(f\"Encoded text sample: {encoded_text[:100]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "387cc9e0-2bdb-4073-8228-fd4195ffc69b",
      "metadata": {
        "id": "387cc9e0-2bdb-4073-8228-fd4195ffc69b"
      },
      "source": [
        "Step 4: input sequence with length 125 tokens, with step = 1 the next sequence will be generated from the previous sequence with a shift of 1 token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "071db4f7-3e88-4863-900b-c570b3c819f0",
      "metadata": {
        "id": "071db4f7-3e88-4863-900b-c570b3c819f0",
        "outputId": "5086d4d0-51af-4742-97d9-0582a25af920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total training sequences: 1115269\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_22526/104445801.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400410390/work/torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  X = torch.tensor(sequences, dtype=torch.long)\n"
          ]
        }
      ],
      "source": [
        "seq_length = 125\n",
        "step = 1\n",
        "sequences = []\n",
        "targets = []\n",
        "\n",
        "for i in range(0, len(encoded_text) - seq_length, step):\n",
        "    sequences.append(encoded_text[i:i + seq_length])\n",
        "    targets.append(encoded_text[i + 1:i + seq_length + 1])  # Full sequence shifted by 1\n",
        "\n",
        "X = torch.tensor(sequences, dtype=torch.long)\n",
        "y = torch.tensor(targets, dtype=torch.long)\n",
        "print(f\"Total training sequences: {X.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3883555-0235-4987-9882-37b271e9f3e1",
      "metadata": {
        "id": "a3883555-0235-4987-9882-37b271e9f3e1",
        "outputId": "cddf7f61-ef6a-429b-97f4-c352b49ead5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "089a7b54-dd59-476d-a9c4-bfd6c153f32a",
      "metadata": {
        "id": "089a7b54-dd59-476d-a9c4-bfd6c153f32a"
      },
      "source": [
        "Step 5: Split the dataset into 80% training and 20% validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4148780d-c212-4003-b50b-50578ef77ee2",
      "metadata": {
        "id": "4148780d-c212-4003-b50b-50578ef77ee2",
        "outputId": "8f3f000d-d05d-4ab3-882f-142233602d3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 892215, Validation set size: 223054\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]}, Validation set size: {X_val.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cc8f450-e25f-450f-9dde-03d977aa4a44",
      "metadata": {
        "id": "6cc8f450-e25f-450f-9dde-03d977aa4a44"
      },
      "source": [
        "Step 6: TransformerBlock with GELU activation gave a better result than RELU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8096807e-9a3b-4983-8663-a8ffe48e7a17",
      "metadata": {
        "id": "8096807e-9a3b-4983-8663-a8ffe48e7a17"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(embed_dim, ff_dim),\n",
        "            nn.GELU(),  # Changed from ReLU to GELU\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(ff_dim, embed_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        norm_x = self.norm1(x)\n",
        "        attn_output, _ = self.attention(norm_x, norm_x, norm_x, attn_mask=mask)\n",
        "        x = x + self.dropout(attn_output)\n",
        "\n",
        "        norm_x = self.norm2(x)\n",
        "        ff_output = self.ff(norm_x)\n",
        "        x = x + ff_output\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c1887ae-3a74-4fdd-a720-b896d17353d8",
      "metadata": {
        "id": "8c1887ae-3a74-4fdd-a720-b896d17353d8"
      },
      "source": [
        "Step 7: Sine and Cosine functions to create unique values for each positionin the sequence. Positional encoding helps the transformer understand position of tokens in the sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a91f3df-879f-4c65-b4ff-6868d5b29ea9",
      "metadata": {
        "id": "9a91f3df-879f-4c65-b4ff-6868d5b29ea9"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def get_positional_encoding(max_len, embed_dim):\n",
        "    pe = torch.zeros(max_len, embed_dim)\n",
        "    position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim))\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "    return pe.unsqueeze(0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5ef5882-b9ab-42f3-8651-b799235992c2",
      "metadata": {
        "id": "e5ef5882-b9ab-42f3-8651-b799235992c2"
      },
      "source": [
        "Step 8: Various combinations of hyperparameters were tested and the following combination gave the best result on training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5c05189-4db9-46c6-a110-dafcc161bb13",
      "metadata": {
        "id": "a5c05189-4db9-46c6-a110-dafcc161bb13"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GPTCharacterModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=192, num_heads=6, ff_dim=768, num_layers=6, max_len=125, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.max_len = max_len\n",
        "        self.position_embedding = get_positional_encoding(self.max_len, embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.transformer_blocks = nn.ModuleList(\n",
        "            [TransformerBlock(embed_dim, num_heads, ff_dim, dropout) for _ in range(num_layers)]\n",
        "        )\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "\n",
        "    def to(self, device):\n",
        "        super().to(device)\n",
        "        self.position_embedding = self.position_embedding.to(device)\n",
        "        return self\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len = x.shape\n",
        "\n",
        "        # Add positional embeddings to token embeddings\n",
        "        x = self.embedding(x) + self.position_embedding[:, :seq_len, :]\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Create causal mask, using triu to ensure each position can only attend to previous positions\n",
        "        mask = torch.triu(torch.ones(seq_len, seq_len, device=x.device) * float('-inf'), diagonal=1)\n",
        "\n",
        "        x = x.permute(1, 0, 2)\n",
        "        for transformer in self.transformer_blocks:\n",
        "            x = transformer(x, mask)\n",
        "\n",
        "        x = x.permute(1, 0, 2)\n",
        "        x = self.norm(x)\n",
        "        return self.fc(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "535cd1e8-2373-4471-9906-b0d9a6ade0e5",
      "metadata": {
        "id": "535cd1e8-2373-4471-9906-b0d9a6ade0e5"
      },
      "source": [
        "Step 9: Traning function where more hyperparameters and learning rate scheduler is defined. Gradient clipping is implemented to avoid exploding gradient.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cfef0f4-6890-45fe-9cd5-cf5bdc9b1fe1",
      "metadata": {
        "id": "5cfef0f4-6890-45fe-9cd5-cf5bdc9b1fe1"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, val_dataloader, epochs=25, lr=0.0003, warmup_steps=1000):\n",
        "    embed_dim = model.embedding.embedding_dim\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.01)\n",
        "\n",
        "    def lr_lambda(step):\n",
        "        if step < warmup_steps:\n",
        "            return float(step) / float(max(1, warmup_steps))\n",
        "        progress = float(step - warmup_steps) / float(max(1, 100000 - warmup_steps))\n",
        "        return max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "\n",
        "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 5\n",
        "    patience_counter = 0\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in dataloader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X_batch)\n",
        "            loss = criterion(output.reshape(-1, vocab_size), y_batch.reshape(-1))\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping to prevent exploding gradients\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_loss / len(dataloader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_dataloader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                output = model(X_batch)\n",
        "                loss = criterion(output.reshape(-1, vocab_size), y_batch.reshape(-1))\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_dataloader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.7f}\")\n",
        "\n",
        "        # Save model if validation loss improves\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': avg_train_loss,\n",
        "                'val_loss': avg_val_loss,\n",
        "            }, \"best_model.pth\")\n",
        "            patience_counter = 0\n",
        "            print(f\"Model saved with improved validation loss: {avg_val_loss:.4f}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "    return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e906369-b937-4ae2-9196-ebf4ac0028b8",
      "metadata": {
        "id": "5e906369-b937-4ae2-9196-ebf4ac0028b8"
      },
      "source": [
        "Step 10: Time for epoch runtime is printed. Intermediate results of the model are printed every 5 epochs and finally the model is saved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfa5edd3-5294-44f0-a684-10713e8c4a60",
      "metadata": {
        "id": "bfa5edd3-5294-44f0-a684-10713e8c4a60",
        "outputId": "b0bb0a35-6eb4-45e8-c5e2-0b5ffe61e96b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameters: 2,694,593\n",
            "Training on: cuda\n",
            "Starting training at 2025-03-12 02:56:16 PM PT\n",
            "Epoch 1/40, Train Loss: 1.6853, Val Loss: 1.2695, LR: 0.0002875\n",
            "Time: 00:04:45 | Total: 00:04:45 | Remaining: 03:05:35\n",
            "\n",
            "----- SAMPLE GENERATIONS -----\n",
            "Sample 1: Before we proceed any further, hear me speak.Before we proceed any further, hear me speak.\n",
            "\n",
            "BAPTISTA:\n",
            "I will do the fair cannot straight the\n",
            "Sample 2: To be, or not to be, that is theTo be, or not to be, that is the state of such a sea\n",
            "That be murder'd by the loss \n",
            "Sample 3: All the world's a stage, and all the men and women merelyAll the world's a stage, and all the men and women merely.\n",
            "\n",
            "DUKE OF YORK:\n",
            "What she doth thou wilt for the f\n",
            "Sample 4: What light through yonder windowWhat light through yonder window the more\n",
            "Of a more strength to leave a blood of t\n",
            "----- END SAMPLES -----\n",
            "\n",
            "Model saved with improved validation loss: 1.2695\n",
            "Epoch 2/40, Train Loss: 1.3248, Val Loss: 1.1795, LR: 0.0002487\n",
            "Time: 00:04:47 | Total: 00:09:33 | Remaining: 03:01:45\n",
            "Model saved with improved validation loss: 1.1795\n",
            "Epoch 3/40, Train Loss: 1.2649, Val Loss: 1.1287, LR: 0.0001908\n",
            "Time: 00:04:48 | Total: 00:14:22 | Remaining: 02:57:22\n",
            "Model saved with improved validation loss: 1.1287\n",
            "Epoch 4/40, Train Loss: 1.2310, Val Loss: 1.0954, LR: 0.0001251\n",
            "Time: 00:04:43 | Total: 00:19:06 | Remaining: 02:52:02\n",
            "Model saved with improved validation loss: 1.0954\n",
            "Epoch 5/40, Train Loss: 1.2091, Val Loss: 1.0744, LR: 0.0000641\n",
            "Time: 00:04:45 | Total: 00:23:52 | Remaining: 02:47:08\n",
            "\n",
            "----- SAMPLE GENERATIONS -----\n",
            "Sample 1: Before we proceed any further, hear me speak.Before we proceed any further, hear me speak.\n",
            "\n",
            "CLARENCE:\n",
            "I cannot meet him for that the foreign\n",
            "Sample 2: To be, or not to be, that is theTo be, or not to be, that is the deadly boy.\n",
            "\n",
            "CLARENCE:\n",
            "I have a thousand services\n",
            "Sample 3: All the world's a stage, and all the men and women merelyAll the world's a stage, and all the men and women merely.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "That shall be be contented to t\n",
            "Sample 4: What light through yonder windowWhat light through yonder windows and words?\n",
            "\n",
            "Second Murderer:\n",
            "No, no; it is the t\n",
            "----- END SAMPLES -----\n",
            "\n",
            "Model saved with improved validation loss: 1.0744\n",
            "Epoch 6/40, Train Loss: 1.1960, Val Loss: 1.0633, LR: 0.0000300\n",
            "Time: 00:04:42 | Total: 00:28:36 | Remaining: 02:42:05\n",
            "Model saved with improved validation loss: 1.0633\n",
            "Epoch 7/40, Train Loss: 1.1907, Val Loss: 1.0579, LR: 0.0000300\n",
            "Time: 00:04:46 | Total: 00:33:22 | Remaining: 02:37:20\n",
            "Model saved with improved validation loss: 1.0579\n",
            "Epoch 8/40, Train Loss: 1.1874, Val Loss: 1.0528, LR: 0.0000300\n",
            "Time: 00:04:42 | Total: 00:38:05 | Remaining: 02:32:20\n",
            "Model saved with improved validation loss: 1.0528\n",
            "Epoch 9/40, Train Loss: 1.1846, Val Loss: 1.0488, LR: 0.0000464\n",
            "Time: 00:04:36 | Total: 00:42:41 | Remaining: 02:27:03\n",
            "Model saved with improved validation loss: 1.0488\n",
            "Epoch 10/40, Train Loss: 1.1848, Val Loss: 1.0473, LR: 0.0001028\n",
            "Time: 00:04:35 | Total: 00:47:17 | Remaining: 02:21:52\n",
            "\n",
            "----- SAMPLE GENERATIONS -----\n",
            "Sample 1: Before we proceed any further, hear me speak.Before we proceed any further, hear me speak.\n",
            "\n",
            "First Senator:\n",
            "You are a man will be mock'd off \n",
            "Sample 2: To be, or not to be, that is theTo be, or not to be, that is the deputy;\n",
            "That I should be thus supply that would s\n",
            "Sample 3: All the world's a stage, and all the men and women merelyAll the world's a stage, and all the men and women merely\n",
            "with such a silver sing is to some complexion, an\n",
            "Sample 4: What light through yonder windowWhat light through yonder windows for his soul.\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "But shall I kn\n",
            "----- END SAMPLES -----\n",
            "\n",
            "Model saved with improved validation loss: 1.0473\n",
            "Epoch 11/40, Train Loss: 1.1847, Val Loss: 1.0429, LR: 0.0001683\n",
            "Time: 00:04:52 | Total: 00:52:10 | Remaining: 02:17:33\n",
            "Model saved with improved validation loss: 1.0429\n",
            "Epoch 12/40, Train Loss: 1.1821, Val Loss: 1.0359, LR: 0.0002303\n",
            "Time: 00:04:51 | Total: 00:57:02 | Remaining: 02:13:06\n",
            "Model saved with improved validation loss: 1.0359\n",
            "Epoch 13/40, Train Loss: 1.1761, Val Loss: 1.0247, LR: 0.0002768\n",
            "Time: 00:04:50 | Total: 01:01:53 | Remaining: 02:08:32\n",
            "Model saved with improved validation loss: 1.0247\n",
            "Epoch 14/40, Train Loss: 1.1672, Val Loss: 1.0119, LR: 0.0002989\n",
            "Time: 00:04:52 | Total: 01:06:45 | Remaining: 02:03:59\n",
            "Model saved with improved validation loss: 1.0119\n",
            "Epoch 15/40, Train Loss: 1.1560, Val Loss: 0.9952, LR: 0.0002923\n",
            "Time: 00:04:50 | Total: 01:11:36 | Remaining: 01:59:20\n",
            "\n",
            "----- SAMPLE GENERATIONS -----\n",
            "Sample 1: Before we proceed any further, hear me speak.Before we proceed any further, hear me speak.\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "I will be so content.\n",
            "\n",
            "DUCHES\n",
            "Sample 2: To be, or not to be, that is theTo be, or not to be, that is the fire\n",
            "Which they would be with such a common state\n",
            "Sample 3: All the world's a stage, and all the men and women merelyAll the world's a stage, and all the men and women merely.\n",
            "\n",
            "DUKE OF AUMERLE:\n",
            "How came you there?\n",
            "\n",
            "DUKE OF Y\n",
            "Sample 4: What light through yonder windowWhat light through yonder windows are they?\n",
            "\n",
            "QUEEN MARGARET:\n",
            "Thou art the matter, \n",
            "----- END SAMPLES -----\n",
            "\n",
            "Model saved with improved validation loss: 0.9952\n",
            "Epoch 16/40, Train Loss: 1.1437, Val Loss: 0.9763, LR: 0.0002584\n",
            "Time: 00:04:53 | Total: 01:16:29 | Remaining: 01:54:44\n",
            "Model saved with improved validation loss: 0.9763\n",
            "Epoch 17/40, Train Loss: 1.1310, Val Loss: 0.9586, LR: 0.0002035\n",
            "Time: 00:04:52 | Total: 01:21:22 | Remaining: 01:50:06\n",
            "Model saved with improved validation loss: 0.9586\n",
            "Epoch 18/40, Train Loss: 1.1186, Val Loss: 0.9418, LR: 0.0001384\n",
            "Time: 00:04:54 | Total: 01:26:17 | Remaining: 01:45:27\n",
            "Model saved with improved validation loss: 0.9418\n",
            "Epoch 19/40, Train Loss: 1.1076, Val Loss: 0.9288, LR: 0.0000755\n",
            "Time: 00:04:37 | Total: 01:30:54 | Remaining: 01:40:28\n",
            "Model saved with improved validation loss: 0.9288\n",
            "Epoch 20/40, Train Loss: 1.0991, Val Loss: 0.9194, LR: 0.0000300\n",
            "Time: 00:04:44 | Total: 01:35:39 | Remaining: 01:35:39\n",
            "\n",
            "----- SAMPLE GENERATIONS -----\n",
            "Sample 1: Before we proceed any further, hear me speak.Before we proceed any further, hear me speak.\n",
            "\n",
            "KING RICHARD III:\n",
            "If you would have said 'Ay,' q\n",
            "Sample 2: To be, or not to be, that is theTo be, or not to be, that is the matter\n",
            "Than the gods above with his spirits of th\n",
            "Sample 3: All the world's a stage, and all the men and women merelyAll the world's a stage, and all the men and women merely\n",
            "to be the world and to be drunk. I have fought it\n",
            "Sample 4: What light through yonder windowWhat light through yonder window from your words?\n",
            "\n",
            "DUKE OF YORK:\n",
            "What, what says h\n",
            "----- END SAMPLES -----\n",
            "\n",
            "Model saved with improved validation loss: 0.9194\n",
            "Epoch 21/40, Train Loss: 1.0951, Val Loss: 0.9162, LR: 0.0000300\n",
            "Time: 00:04:52 | Total: 01:40:33 | Remaining: 01:30:58\n",
            "Model saved with improved validation loss: 0.9162\n",
            "Epoch 22/40, Train Loss: 1.0939, Val Loss: 0.9133, LR: 0.0000300\n",
            "Time: 00:04:43 | Total: 01:45:16 | Remaining: 01:26:08\n",
            "Model saved with improved validation loss: 0.9133\n",
            "Epoch 23/40, Train Loss: 1.0929, Val Loss: 0.9118, LR: 0.0000371\n",
            "Time: 00:04:42 | Total: 01:49:59 | Remaining: 01:21:18\n",
            "Model saved with improved validation loss: 0.9118\n",
            "Epoch 24/40, Train Loss: 1.0949, Val Loss: 0.9149, LR: 0.0000902\n",
            "Time: 00:04:43 | Total: 01:54:43 | Remaining: 01:16:29\n",
            "Epoch 25/40, Train Loss: 1.1000, Val Loss: 0.9196, LR: 0.0001549\n",
            "Time: 00:04:42 | Total: 01:59:26 | Remaining: 01:11:39\n",
            "\n",
            "----- SAMPLE GENERATIONS -----\n",
            "Sample 1: Before we proceed any further, hear me speak.Before we proceed any further, hear me speak.\n",
            "\n",
            "CAMILLO:\n",
            "Sir, I will take it off.\n",
            "\n",
            "POLIXENES:\n",
            "If\n",
            "Sample 2: To be, or not to be, that is theTo be, or not to be, that is the world\n",
            "Of her as well as if I am sure of me.\n",
            "\n",
            "BUCK\n",
            "Sample 3: All the world's a stage, and all the men and women merelyAll the world's a stage, and all the men and women merely\n",
            "to his majesty. What shall he be of death?\n",
            "\n",
            "DUKE \n",
            "Sample 4: What light through yonder windowWhat light through yonder windows and graces,\n",
            "That thou wilt dispress thy country'\n",
            "----- END SAMPLES -----\n",
            "\n",
            "Epoch 26/40, Train Loss: 1.1053, Val Loss: 0.9247, LR: 0.0002186\n",
            "Time: 00:04:44 | Total: 02:04:11 | Remaining: 01:06:52\n",
            "Epoch 27/40, Train Loss: 1.1089, Val Loss: 0.9299, LR: 0.0002691\n",
            "Time: 00:04:44 | Total: 02:08:55 | Remaining: 01:02:04\n",
            "Epoch 28/40, Train Loss: 1.1094, Val Loss: 0.9257, LR: 0.0002967\n",
            "Time: 00:04:44 | Total: 02:13:40 | Remaining: 00:57:17\n",
            "Epoch 29/40, Train Loss: 1.1066, Val Loss: 0.9209, LR: 0.0002960\n",
            "Time: 00:04:44 | Total: 02:18:24 | Remaining: 00:52:30\n",
            "Epoch 30/40, Train Loss: 1.1006, Val Loss: 0.9094, LR: 0.0002672\n",
            "Time: 00:04:48 | Total: 02:23:13 | Remaining: 00:47:44\n",
            "\n",
            "----- SAMPLE GENERATIONS -----\n",
            "Sample 1: Before we proceed any further, hear me speak.Before we proceed any further, hear me speak.\n",
            "\n",
            "LUCIO:\n",
            "I have done, sir.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "And yo\n",
            "Sample 2: To be, or not to be, that is theTo be, or not to be, that is the power\n",
            "That thou wouldst be not so.\n",
            "\n",
            "CORIOLANUS:\n",
            "T\n",
            "Sample 3: All the world's a stage, and all the men and women merelyAll the world's a stage, and all the men and women merely\n",
            "In battle, for he hath been a month of me\n",
            "To be t\n",
            "Sample 4: What light through yonder windowWhat light through yonder windows that you have done,\n",
            "But when you should be honou\n",
            "----- END SAMPLES -----\n",
            "\n",
            "Model saved with improved validation loss: 0.9094\n",
            "Epoch 31/40, Train Loss: 1.0926, Val Loss: 0.8971, LR: 0.0002159\n",
            "Time: 00:04:47 | Total: 02:28:01 | Remaining: 00:42:58\n",
            "Model saved with improved validation loss: 0.8971\n",
            "Epoch 32/40, Train Loss: 1.0833, Val Loss: 0.8843, LR: 0.0001518\n",
            "Time: 00:04:46 | Total: 02:32:48 | Remaining: 00:38:12\n",
            "Model saved with improved validation loss: 0.8843\n",
            "Epoch 33/40, Train Loss: 1.0739, Val Loss: 0.8718, LR: 0.0000875\n",
            "Time: 00:04:45 | Total: 02:37:33 | Remaining: 00:33:25\n",
            "Model saved with improved validation loss: 0.8718\n",
            "Epoch 34/40, Train Loss: 1.0662, Val Loss: 0.8631, LR: 0.0000351\n",
            "Time: 00:04:45 | Total: 02:42:18 | Remaining: 00:28:38\n",
            "Model saved with improved validation loss: 0.8631\n",
            "Epoch 35/40, Train Loss: 1.0618, Val Loss: 0.8599, LR: 0.0000300\n",
            "Time: 00:04:39 | Total: 02:46:58 | Remaining: 00:23:51\n",
            "\n",
            "----- SAMPLE GENERATIONS -----\n",
            "Sample 1: Before we proceed any further, hear me speak.Before we proceed any further, hear me speak.\n",
            "\n",
            "BISHOP OF CARLISLE:\n",
            "I do beseech you, sir, becau\n",
            "Sample 2: To be, or not to be, that is theTo be, or not to be, that is the deed.\n",
            "\n",
            "PRINCE EDWARD:\n",
            "Then, Warwick, Warwick, and\n",
            "Sample 3: All the world's a stage, and all the men and women merelyAll the world's a stage, and all the men and women merely.\n",
            "\n",
            "DUKE OF YORK:\n",
            "As I have done thee better than t\n",
            "Sample 4: What light through yonder windowWhat light through yonder windows to the world?\n",
            "\n",
            "Second Murderer:\n",
            "And the noble se\n",
            "----- END SAMPLES -----\n",
            "\n",
            "Model saved with improved validation loss: 0.8599\n",
            "Epoch 36/40, Train Loss: 1.0605, Val Loss: 0.8581, LR: 0.0000300\n",
            "Time: 00:04:35 | Total: 02:51:34 | Remaining: 00:19:03\n",
            "Model saved with improved validation loss: 0.8581\n",
            "Epoch 37/40, Train Loss: 1.0600, Val Loss: 0.8561, LR: 0.0000300\n",
            "Time: 00:04:36 | Total: 02:56:10 | Remaining: 00:14:17\n",
            "Model saved with improved validation loss: 0.8561\n",
            "Epoch 38/40, Train Loss: 1.0611, Val Loss: 0.8597, LR: 0.0000781\n",
            "Time: 00:04:36 | Total: 03:00:47 | Remaining: 00:09:30\n",
            "Epoch 39/40, Train Loss: 1.0666, Val Loss: 0.8661, LR: 0.0001414\n",
            "Time: 00:04:33 | Total: 03:05:21 | Remaining: 00:04:45\n",
            "Epoch 40/40, Train Loss: 1.0733, Val Loss: 0.8744, LR: 0.0002064\n",
            "Time: 00:04:35 | Total: 03:09:56 | Remaining: 00:00:00\n",
            "\n",
            "----- SAMPLE GENERATIONS -----\n",
            "Sample 1: Before we proceed any further, hear me speak.Before we proceed any further, hear me speak.\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "No, my good lord; I pray you, si\n",
            "Sample 2: To be, or not to be, that is theTo be, or not to be, that is the world of me,\n",
            "The witness of his foot and all my l\n",
            "Sample 3: All the world's a stage, and all the men and women merelyAll the world's a stage, and all the men and women merely.\n",
            "\n",
            "TRANIO:\n",
            "Thou art a traitor, for thy father's th\n",
            "Sample 4: What light through yonder windowWhat light through yonder windows from the head\n",
            "And look upon me, the devil's son \n",
            "----- END SAMPLES -----\n",
            "\n",
            "Total training time: 03:09:57\n",
            "\n",
            "----- FINAL GENERATIONS -----\n",
            "Final Sample 1: Before we proceed any further, hear me speak.Before we proceed any further, hear me speak.\n",
            "\n",
            "LUCENTIO:\n",
            "Then is a word in this business which he should be\n",
            "presently he shall be a dozen to the \n",
            "Final Sample 2: To be, or not to be, that is theTo be, or not to be, that is the first thing\n",
            "May be a fool, that thou wilt purchase thee and\n",
            "Thy mind shall be thy grief: I'll not m\n",
            "Final Sample 3: All the world's a stage, and all the men and women merelyAll the world's a stage, and all the men and women merely\n",
            "Than the which he hath appeared in the state\n",
            "And show'd the steel of my mother's hands,\n",
            "That we wil\n",
            "Final Sample 4: What light through yonder windowWhat light through yonder windows now,\n",
            "And heaven show the household of York\n",
            "May be a prophetess of the poor heart.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "----- END FINAL SAMPLES -----\n",
            "\n",
            "Training completed at 2025-03-12 06:06:15 PM PT\n",
            "Final model saved as final_model.pth\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import datetime\n",
        "from pytz import timezone\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "batch_size = 64\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "val_data = TensorDataset(X_val, y_val)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Initialize model and move to device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = GPTCharacterModel(vocab_size).to(device)\n",
        "\n",
        "# Print model summary\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Training on: {device}\")\n",
        "\n",
        "# Function to get current time in Pacific Time with 12-hour format\n",
        "def get_pt_time():\n",
        "    pacific = timezone('US/Pacific')\n",
        "    now = datetime.datetime.now(pacific)\n",
        "    return now.strftime(\"%Y-%m-%d %I:%M:%S %p PT\")\n",
        "\n",
        "# Function to format seconds into HH:MM:SS\n",
        "def format_time(seconds):\n",
        "    hours, remainder = divmod(int(seconds), 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
        "\n",
        "# Text generation function for intermediate predictions\n",
        "def generate_intermediate_text(model, start_text=\"The \", length=100, temperature=0.7, top_p=0.9):\n",
        "    device = model.embedding.weight.device\n",
        "    model.eval()\n",
        "\n",
        "    # Handle potential unknown characters in start text\n",
        "    generated = []\n",
        "    for ch in start_text:\n",
        "        if ch in char_to_idx:\n",
        "            generated.append(char_to_idx[ch])\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    input_seq = torch.tensor(generated, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    for _ in range(length):\n",
        "        with torch.no_grad():\n",
        "            # Get model output for the current sequence\n",
        "            output = model(input_seq)[:, -1, :] / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(output, dim=-1)\n",
        "\n",
        "            # Nucleus (top-p) sampling\n",
        "            sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
        "            cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
        "\n",
        "            # Remove tokens with cumulative probability above the threshold\n",
        "            sorted_indices_to_remove = cumulative_probs > top_p\n",
        "            # Shift the indices to the right to keep the first token above the threshold\n",
        "            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "            sorted_indices_to_remove[..., 0] = 0\n",
        "\n",
        "            # Create a mask for allowed indices\n",
        "            indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n",
        "            probs = probs.masked_fill(indices_to_remove, 0.0)\n",
        "\n",
        "            # Sample from the filtered distribution\n",
        "            next_char = torch.multinomial(probs, 1).item()\n",
        "\n",
        "            generated.append(next_char)\n",
        "\n",
        "            # Update input sequence for next iteration\n",
        "            input_seq = torch.tensor(generated[-model.max_len:], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    return start_text + \"\".join(idx_to_char[idx] for idx in generated)\n",
        "\n",
        "# Modify train function to track time and generate sample text\n",
        "def train_with_timing_and_samples(model, dataloader, val_dataloader, epochs=25, lr=0.0003, warmup_steps=1000):\n",
        "    embed_dim = model.embedding.embedding_dim\n",
        "    device = model.embedding.weight.device\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.01)\n",
        "\n",
        "    # Learning rate scheduler with linear warmup and cosine decay\n",
        "    def lr_lambda(step):\n",
        "        # Linear warmup for warmup_steps steps\n",
        "        if step < warmup_steps:\n",
        "            return float(step) / float(max(1, warmup_steps))\n",
        "        # Cosine learning rate decay\n",
        "        progress = float(step - warmup_steps) / float(max(1, 100000 - warmup_steps))\n",
        "        return max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "\n",
        "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 25\n",
        "    patience_counter = 0\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    total_start_time = time.time()\n",
        "\n",
        "    # Sample prompts for consistent evaluation\n",
        "    sample_prompts = [\n",
        "        \"Before we proceed any further, hear me speak.\",\n",
        "        \"To be, or not to be, that is the\",\n",
        "        \"All the world's a stage, and all the men and women merely\",\n",
        "        \"What light through yonder window\"\n",
        "    ]\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in dataloader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X_batch)  # Shape: [batch_size, seq_length, vocab_size]\n",
        "            loss = criterion(output.reshape(-1, vocab_size), y_batch.reshape(-1))  # Flatten\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping to prevent exploding gradients\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_loss / len(dataloader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_dataloader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                output = model(X_batch)\n",
        "                loss = criterion(output.reshape(-1, vocab_size), y_batch.reshape(-1))\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_dataloader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Calculate time for this epoch\n",
        "        epoch_time = time.time() - epoch_start_time\n",
        "        elapsed_time = time.time() - total_start_time\n",
        "\n",
        "        # Estimate time remaining\n",
        "        avg_epoch_time = elapsed_time / (epoch + 1)\n",
        "        remaining_epochs = epochs - (epoch + 1)\n",
        "        estimated_time_remaining = avg_epoch_time * remaining_epochs\n",
        "\n",
        "        # Format times using custom function\n",
        "        epoch_time_str = format_time(epoch_time)\n",
        "        elapsed_time_str = format_time(elapsed_time)\n",
        "        remaining_time_str = format_time(estimated_time_remaining)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.7f}\")\n",
        "        print(f\"Time: {epoch_time_str} | Total: {elapsed_time_str} | Remaining: {remaining_time_str}\")\n",
        "\n",
        "        # Generate sample text every 5 epochs\n",
        "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "            print(\"\\n----- SAMPLE GENERATIONS -----\")\n",
        "            for i, prompt in enumerate(sample_prompts):\n",
        "                generated = generate_intermediate_text(model, start_text=prompt, length=50, temperature=0.7)\n",
        "                print(f\"Sample {i+1}: {generated}\")\n",
        "            print(\"----- END SAMPLES -----\\n\")\n",
        "\n",
        "        # Save model if validation loss improves\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': avg_train_loss,\n",
        "                'val_loss': avg_val_loss,\n",
        "            }, \"best_model.pth\")\n",
        "            patience_counter = 0\n",
        "            print(f\"Model saved with improved validation loss: {avg_val_loss:.4f}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "    total_time = time.time() - total_start_time\n",
        "    total_time_str = format_time(total_time)\n",
        "    print(f\"Total training time: {total_time_str}\")\n",
        "\n",
        "    # Generate final samples\n",
        "    print(\"\\n----- FINAL GENERATIONS -----\")\n",
        "    for i, prompt in enumerate(sample_prompts):\n",
        "        generated = generate_intermediate_text(model, start_text=prompt, length=100, temperature=0.6)\n",
        "        print(f\"Final Sample {i+1}: {generated}\")\n",
        "    print(\"----- END FINAL SAMPLES -----\\n\")\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "# Train with timing information and sample generation\n",
        "print(f\"Starting training at {get_pt_time()}\")\n",
        "train_losses, val_losses = train_with_timing_and_samples(model, train_loader, val_loader, epochs=40)\n",
        "\n",
        "# Save final model\n",
        "torch.save(model.state_dict(), \"final_model.pth\")\n",
        "print(f\"Training completed at {get_pt_time()}\")\n",
        "print(\"Final model saved as final_model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09d3a9f4-562b-445f-8e33-5d04e9f3d4a4",
      "metadata": {
        "id": "09d3a9f4-562b-445f-8e33-5d04e9f3d4a4"
      },
      "source": [
        "Step 11: Finally the saved model is loaded, instantiated and output of length 500 is generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1d7f944-f6ff-43df-a957-cd137530d90d",
      "metadata": {
        "id": "e1d7f944-f6ff-43df-a957-cd137530d90d",
        "outputId": "9c1d28c4-4ec8-4196-d678-957fc6200b57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated text:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "First Citizen:\n",
            "You may peril our ears in the service of his honour,\n",
            "May be but prayed with him. I forgive it to this:\n",
            "I will forget such necessity of my peace\n",
            "Be profess'd to me, whose sovereignty\n",
            "Would send for me again.\n",
            "\n",
            "CLAUDIO:\n",
            "Then, if I cannot do.\n",
            "\n",
            "ISABELLA:\n",
            "Be gone.\n",
            "\n",
            "LUCIO:\n",
            "Ay, here comes my true service.\n",
            "\n",
            "ANGELO:\n",
            "And to see looks fell by the lower things will not do\n",
            "But this restraint while he hath been feels\n",
            "The heavy mother doth continue their own.\n",
            "\n",
            "ROMEO:\n",
            "In this new man that we have learn'd my brother's\n",
            "Commong me to this king; and, if he cannot,\n",
            "See that the heavens shall come the day of me.\n",
            "\n",
            "BRUTUS:\n",
            "How is't well?\n",
            "\n",
            "SICINIUS:\n",
            "No, no, no;\n",
            "I am no tribunes: let's see the consuls in the note.\n",
            "\n",
            "MENENIUS:\n",
            "I am now too unprovided, for the suburbs of heaven\n",
            "Be ran as following and in the crown?\n",
            "\n",
            "First Senator:\n",
            "So he that will be thine.\n",
            "\n",
            "Second Murderer:\n",
            "So that you do not show yo\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Recreate character mappings from input.txt\n",
        "with open(\"input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
        "idx_to_char = {idx: char for idx, char in enumerate(chars)}\n",
        "vocab_size = len(chars)\n",
        "\n",
        "# Instantiate the model with the same parameters used during training\n",
        "model = GPTCharacterModel(vocab_size=vocab_size, embed_dim=192, num_heads=6, ff_dim=768, num_layers=6, max_len=125, dropout=0.2)\n",
        "\n",
        "# Load the saved state_dict\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(torch.load(\"final_model.pth\", map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "def generate_text(model, start_text, length=500, temperature=0.8, top_k=20):\n",
        "    device = model.embedding.weight.device\n",
        "    generated = [char_to_idx[ch] for ch in start_text if ch in char_to_idx]\n",
        "    input_seq = torch.tensor(generated, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    for _ in range(length):\n",
        "        with torch.no_grad():\n",
        "            output = model(input_seq)[:, -1, :] / temperature\n",
        "            probs = torch.softmax(output, dim=-1)\n",
        "            top_k_probs, top_k_ids = probs.topk(top_k, dim=-1)\n",
        "            next_char_idx = torch.multinomial(top_k_probs, 1).item()\n",
        "            next_char = top_k_ids[0, next_char_idx].item()\n",
        "            generated.append(next_char)\n",
        "            input_seq = torch.tensor(generated[-model.max_len:], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            if i % 50 == 0:  # Print every 50 characters\n",
        "                print(f\"Step {i}: {' '.join(idx_to_char[idx] for idx in generated[-50:])}\")\n",
        "\n",
        "    return \"\".join(idx_to_char[idx] for idx in generated)\n",
        "\n",
        "# Test the function\n",
        "start_prompt = \"Before we proceed any further, hear me speak.\"\n",
        "generated_text = generate_text(model, start_prompt, length=900)\n",
        "print(f\"Generated text:\\n{generated_text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 12: Train-Validation loss curve is plotted"
      ],
      "metadata": {
        "id": "F3RZuKCeE_Lo"
      },
      "id": "F3RZuKCeE_Lo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cfaae7e-5af5-4eb2-b41b-c751b665a50e",
      "metadata": {
        "id": "2cfaae7e-5af5-4eb2-b41b-c751b665a50e",
        "outputId": "1cd0b71f-465d-4e62-98be-011e491f875e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(val_losses, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Train-Validation Loss Curve\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 6759172,
          "sourceId": 10878485,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30919,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}